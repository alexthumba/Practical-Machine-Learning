---
title: "Practical Machine Learning Course Project"
author: "Alex Thumba"
date: "Monday, December 15, 2014"
output: html_document
---
Project

Practical Machine Learning Assignment Submission

```{r}
#packages for analysis
library(caret) #Classification and Regression Training
library(randomForest)#Random forest for classification and regression
library(rpart)# Regressive Partitioning and Regression trees
library(rpart.plot)# Decision Tree plot
set.seed(1234)
#data loading from computer to R session (training and test data) and replacing the missing data with "NA"
pmltrainingset <- read.csv("C:/Users/alexthumba/Downloads/Coursera/Machine Learning/ML assignment/pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
pmltestingset <- read.csv("C:/Users/alexthumba/Downloads/Coursera/Machine Learning/ML assignment/pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
#checking the diamension of the datasets, training and testing
dim(pmltrainingset)
dim(pmltestingset)
#removing the columns with missing values
pmltrainingset<-pmltrainingset[,colSums(is.na(pmltrainingset)) == 0]
pmltestingset <-pmltestingset[,colSums(is.na(pmltestingset)) == 0]
# removing the variables which doesnt have importance in the analysis 
#user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window (columns 1 to 7).
pmltrainingset   <-pmltrainingset[,-c(1:7)]
pmltestingset <-pmltestingset[,-c(1:7)]
#diamension of the modified dataset
dim(pmltrainingset)
dim(pmltestingset)

#In order to perform cross-validation, the training data set is partionned into 2 sets
#subTraining (75%) and subTest (25%).
#This will be performed using random subsampling without replacement.

subsamples <- createDataPartition(y=pmltrainingset$classe, p=0.75, list=FALSE)
subTraining <- pmltrainingset[subsamples, ] 
subTesting <- pmltrainingset[-subsamples, ]
#diamensions of the partitioned  dataset
dim(subTraining)
dim(subTesting)

#plot of frequency of 'classe' at various levels (A,B,C,D,E) in subtraining data
#The variable "classe" contains 5 levels: A, B, C, D and E.

plot(subTraining$classe, main="size of class levels in subtraining data", xlab="classe levels", ylab="Frequency")

#prediction model Using Decision Tree

decision.tree.model <- rpart(classe ~ ., data=subTraining, method="class")

# Predicting using decision tree:
decision.tree.prediction <- predict(decision.tree.model, subTesting, type = "class")

# Plot of the Decision Tree
rpart.plot(decision.tree.model, main="Classification Tree", extra=102, under=TRUE, faclen=0)
confusionMatrix(decision.tree.prediction, subTesting$classe)

#prediction model Using Random Forest
random.forest.model <- randomForest(classe ~. , data=subTraining, method="class")
# Predicting using random forest:
random.forest.prediction<- predict(random.forest.model, subTesting, type = "class")
confusionMatrix(random.forest.prediction, subTesting$classe)
#Forest algorithm performed better than Decision Trees
#Accuracy for Random Forest model was 0.9957 (95% CI: (0.9935, 0.9973)) compared to 
#0.7394 (95% CI: (0.7269, 0.7516)) for Decision Tree model.
#So the random Forest model is choosen.
# predict outcome levels on the original Testing data set using Random Forest algorithm

```

Conclusion

We can see from the analysis that the Random Forest performed better than Decision Trees.
Accuracy for Random Forest model was 0.9957 (95% CI: (0.9935, 0.9973)) and that of decision tree was 0.7394 (95% CI: (0.7269, 0.7516).So the random Forest model is choosen. The accuracy of the model is 0.995. The expected out-of-sample error is estimated at 0.005, or 0.5%.Our Test data set comprises 20 cases. With an accuracy above 99% on our cross-validation data, we can expect that very few, or none, of the test samples will be missclassified.

```{r}
predictfinal <- predict(random.forest.model, pmltestingset, type="class")
predictfinal
```

```{r}
# Write files for submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictfinal)
```

